{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red9\green80\blue208;\red0\green0\blue0;\red255\green255\blue255;
\red0\green0\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c41176\c85098;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;
\cssrgb\c0\c0\c100000;\csgenericrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh14740\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs28 \cf0 This document will log progress towards master thesis submission to Sofia University - FMI. \
The chosen area is object segmentation / scene understanding through deep learning. \
Possibly applications: retail; improved image quality. There are further alternatives, of course. \
\
Structure of the document: \
1. Log progress stages. \
2. References\
3. Sketch basic structure of the master thesis. \
4. Misc\
\
1. Log progress stages. \
Until December 2017:\
read several papers on object segmentation and/or deep learning. \
(optional) Install sample image pipeline for possible analysis.\
Sketch thesis paper, start writing. \
\
1.1 Nov 5: \
	Finished reading through book Learning TensorFlow\
by Tom Hope; Yehezkel S. Resheff; Itay Lieder\
\pard\pardeftab720\partightenfactor0
\cf0 \
Good introduction. A lot of effort is spent on its dev-ops side. A note to VGG as an alternative to Inception. \
\
Due Nov 12: \
	1.1.due: a Sketch thesis structure\
	1.1.due: b Write a plan with expected dates of finishing different parts.\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
1.2 Dec 2: \
Work on sample paper. \
\
1.3 Dec 28. \
Current progress:\
Looked at places205, places365 database\
Installed TF-GPU, TF-GPU on Anaconda; issue with places-nn installing on Windows. Issue was related to the use of torch, which is not readily available on Windows. \
To do: \
Write introduction of paper\
Play with several available TF tutorials, to train sample Inception-v3 models as a practice; train on VGG as a practice; run places inference (on a CPU-VM)\
Eval changing of paper. Could there be a suitable retail/fashion alternative? Or a simpler Inception one for MS? \
\
1.4.A\
Reviewed conditions for the thesis. Should match requirements; need to match dev + geometry/mathematics. \
Reviewed topic. Should be ok. \
I did not do some of the tutorials yet - relate to next step. \
1.4.B\
To do: \
	1.4.B.1 Read on LTSM networks; need to find the reference but image parsing is supposedly better with LTSM\
	1.4.B.2 Read more on places305; do sample tests \
	1.4.B.3 Do tutorials on:\
		Torch7 - because places365 is on it\
		TensorFlow - because it is common\
		CNTK - because of my Windows machine\
	1.4.B.4 Practice NN from scratch; practice transfer learning for image recognition\
	1.4.B.5 Capsules for image parsing??? Maybe\
1.4.C\
Finished:\
	1.4.C.1. LTSM is a cell; RNN inside connected to others. I wonder why it worked well for image parsing. \
\
Jan 1, 2018\
Common information on capsule networks. I watched Siraj\'92s introduction:\
https://www.youtube.com/watch?v=VKoLGnq15RM\
\
It might be possible to run a paper with image parsing as something novel. I might want to build some common practice with the tutorials (steps 1.4.B.3, 1.4.B.4) as a safe option to have something reasonable for the Master\'92s; otherwise capsules seem promising as personal interest. \
\
Next: steps 1.4.B.3, 1.4.B.4, which are to build common training from scratch and from transfer training. \
\
\
April 15, 2018\
\
Been busy on \'92in-real-life\'92 tasks. \
So far the progress is running tutorials over example image finding (Fashion MNIST): reading on capsules and FCN. I found example datasets for image parsing, which is a positive development. \
\
I will be busy on professional and \'91in-real-life\'92 tasks, so I would have limited time in the next month. Next is passing the arcGIS class. \
\
April 21, 2018\
\
Worked on the other class. \
Downgraded to CUDA 9.0, since there was a mismatch between TensorFlow and supported CUDA. I upgraded Tensorflow to tensor flow-1.8 rc0-gpu.\
\
\
\
February 6, 2019\
\
Wow, it is 2019. An overdue update. I will log why I have not logged progress in a period of 10 months, log re-evaluated goals and write next steps. \
\
Why I have not logged progress in a period of 10 months:\
There were several important external priorities, professional and personal related, that I had to commit to in this time frame. They are mostly finished, but it is visible that there is a gap in the progress on the master thesis. \
\
Evaluated goals.\
I do want to finish the master thesis and associated commitments going beyond it. The goals are: 1. Have fun writing the thesis, 2. Learn on capsule networks and 3. Finish off scene parsing prototype. \
I have to combine this commitment with commitments to myself; I cannot spend innumerate amount of time on the thesis. It is fun to delve into all aspects related to development the thesis, but I have external commitments as well. It will be a Pyrrhic victory if I let down some of those other areas. \
\
\
\
What has changed and Next steps: \
There is support for DNN through Tensorflow and CNTK on Windows 10 (current available hardware), available AWS, Azure services. To get progress would use the available Anaconda on Windows 10 setup. \
Here I will outline time frames, assumptions and outline of the thesis and research. \
\
Time frames: I have to spend time on the thesis; but budget the time so that I cannot go overboard with it. If I spend too much time for a long duration, I will lose track of what the value of the research effort is. Therefore, I will spend the next 1.5-2 months with a focused effort on the thesis. I will spend time on reading and computation steps to see how far it will take the effort. I also have to reach out to other research-oriented individuals, so that there is some feedback on it. \
\
I will evaluate back the progress by mid-April. \
\
I will put a limit on work for no more than 7 hours on Saturdays/holidays and no more than 2 hours if external commitments are present. This is to keep my effort within reasonable limits; I have to put effort for my personal wellness. \
\
Because of this I have to limit the scope of the thesis; I will evaluate how it goes on a later stage. The thesis might not be the grandest one - but at least it will keep the effort fun and make me happy to progress :) \
\
Outline of the thesis: \
Several efforts are possible (which is why I have to limit the scope one at a time); to log them now the visible ones I see are: Intel RealSense 3D scanning; Implement scene parsing with CNNs and DNN Network capsule; Object detection; OpenCV implementation for a task; iOS Core ML2 implementation. \
These are all fun mini-projects; but I have to pick and progress on one. To progress on one of them, I am looking at  \'91Implement scene parsing with CNNs and DNN Network capsule\'92. \
\
Tutorials to do: \
Transfer learning tutorial\
\
To implement: \
Implement Tensorflow tutorial on image scene parsing dataset using transfer learning. Would be used as a baseline.\
Implement a small CNN, custom, small, pruning - would be used to see how a small-parameter CNN compares on the dataset. \
Implement a capsule network with routing - evaluate whether the performance of the capsule network is competitive. <\'97 this is as close to an end-goal of the project for the thesis as possible\
\
 If time commitments do not permit to reach the full scale of the implementation, evaluate the scope. Due consequent updates. \
 \
\
\
\
\
\
\
\
2. References:\
\
On FCN : https://github.com/shelhamer/fcn.berkeleyvision.org :: {\field{\*\fldinst{HYPERLINK "https://www.google.bg/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&ved=2ahUKEwj-y4upib3aAhVBjCwKHZ73AVoQFjABegQIABBC&url=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~jonlong%2Flong_shelhamer_fcn.pdf&usg=AOvVaw1OZIT1dpO9NAS45hB7mhG8"}}{\fldrslt Fully Convolutional Networks for Semantic Segmentation}} :: {\field{\*\fldinst{HYPERLINK "https://www.google.bg/url?sa=t&rct=j&q=&esrc=s&source=web&cd=8&ved=0ahUKEwiOgMXCib3aAhWHBiwKHUcwCfgQFgg8MAc&url=https%3A%2F%2Fgithub.com%2Fshekkizh%2FFCN.tensorflow&usg=AOvVaw00fws_w_X_jGl10_eWklnO"}}{\fldrslt GitHub - shekkizh/FCN.tensorflow: Tensorflow implementation of Fully ...}}\
\
\
\
\
\pard\pardeftab720\partightenfactor0
\cf2 \expnd0\expndtw0\kerning0
\ul \ulc2 http://www.cs.nyu.edu/~yann/talks/lecun-20130623-cvpr-sunw.pdf\
\
\pard\pardeftab720\partightenfactor0
\cf0 \ulnone \'97\
Yann LeCun, Scene Understanding With Deep Learning\
\
References from it: \
\pard\pardeftab720\sl620\sa240\partightenfactor0
\cf3 \cb4 [Couprie, Farabet, Najman, LeCun ICLR 2013] \cb1 \
\cb4 [Couprie et al ICIP 2013] [Couprie et al JMLR under review] \cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 Semantic segmentation: \cf3 \cb4 [Farabet et al. ICML 2012] \
\pard\pardeftab720\sl540\sa240\partightenfactor0
\cf3 \cb1 [Farabet et al. IEEE T. PAMI 2013] \
\cb4 [Farabet et al. ICML 2012] [Farabet et al. IEEE T. PAMI 2013] - see list of cited papers\
\pard\pardeftab720\sl620\sa240\partightenfactor0
\cf5 [Tighe 2010], [Liu 2009]:\cb1 \uc0\u8232 \cf3 \cb4 [Couprie et al ICIP 2013] \cb1 \
\pard\pardeftab720\sl620\sa240\partightenfactor0
\cf3 \cb4 [Couprie, Farabet, Najman, LeCun ICIP 2013] \cb1 \
RGB-D Dataset:\
\cb4 [Silberman et al. 2012] \cb1 \
\'97\
\pard\pardeftab720\partightenfactor0
\cf2 \ul https://medium.com/@eddiesmo/video-object-segmentation-the-basics-758e77321914\cf0 \ulnone \
\
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://github.com/terryum/awesome-deep-learning-papers?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue"}}{\fldrslt \cf2 \ul https://github.com/terryum/awesome-deep-learning-papers?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue}}\cf2 \ul \
\
https://fellowship.ai/blog/hyperparam?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue\
\
https://medium.com/@medhaa/three-things-you-need-to-know-about-machine-learning-99e6f5815aee\
\
http://hyperparameter.space/blog/when-not-to-use-deep-learning/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=Deep%20Learning%20Weekly\
\
\pard\pardeftab720\partightenfactor0

\fs24 \cf6 \ulnone dv \
Fsdfsd\
4. \
Eval A detection of action / situation - a person drowning in sea??? Per Conversation with Peter. \
 \
}