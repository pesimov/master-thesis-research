{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red9\green80\blue208;\red0\green0\blue0;\red0\green0\blue0;
\red255\green255\blue255;\red0\green0\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c41176\c85098;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c0;
\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww22800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs28 \cf0 This document will log progress towards master thesis submission to Sofia University - FMI. \
The chosen area is object segmentation / scene understanding through deep learning. \
Possibly applications: retail; improved image quality. There are further alternatives, of course. \
\
Structure of the document: \
1. Log progress stages. \
2. References\
3. Sketch basic structure of the master thesis. \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 1. Log progress stages. \
Until December 2017:\
read several papers on object segmentation and/or deep learning. \
(optional) Install sample image pipeline for possible analysis.\
Sketch thesis paper, start writing. \
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 2. References:\
\pard\pardeftab720\partightenfactor0
\cf2 \expnd0\expndtw0\kerning0
\ul \ulc2 http://www.cs.nyu.edu/~yann/talks/lecun-20130623-cvpr-sunw.pdf\
\
\pard\pardeftab720\partightenfactor0
\cf0 \ulnone \'97\
Yann LeCun, Scene Understanding With Deep Learning\
\
References from it: \
\pard\pardeftab720\sl620\sa240\partightenfactor0
\cf4 \cb5 \outl0\strokewidth0 \strokec4 [Couprie, Farabet, Najman, LeCun ICLR 2013] \cb1 \
\cb5 [Couprie et al ICIP 2013] [Couprie et al JMLR under review] \cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \outl0\strokewidth0 Semantic segmentation: \cf4 \cb5 \outl0\strokewidth0 \strokec4 [Farabet et al. ICML 2012] \
\pard\pardeftab720\sl540\sa240\partightenfactor0
\cf4 \cb1 [Farabet et al. IEEE T. PAMI 2013] \
\cb5 [Farabet et al. ICML 2012] [Farabet et al. IEEE T. PAMI 2013] - see list of cited papers\
\pard\pardeftab720\sl620\sa240\partightenfactor0
\cf6 \strokec6 [Tighe 2010], [Liu 2009]:\cb1 \uc0\u8232 \cf4 \cb5 \strokec4 [Couprie et al ICIP 2013] \cb1 \
\pard\pardeftab720\sl620\sa240\partightenfactor0
\cf4 \cb5 [Couprie, Farabet, Najman, LeCun ICIP 2013] \cb1 \
RGB-D Dataset:\
\cb5 [Silberman et al. 2012] \cb1 \
\'97\
\pard\pardeftab720\partightenfactor0
\cf2 \ul \ulc2 \outl0\strokewidth0 https://medium.com/@eddiesmo/video-object-segmentation-the-basics-758e77321914\cf0 \ulnone \
\
\pard\pardeftab720\partightenfactor0
{\field{\*\fldinst{HYPERLINK "https://github.com/terryum/awesome-deep-learning-papers?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue"}}{\fldrslt \cf2 \ul \ulc2 https://github.com/terryum/awesome-deep-learning-papers?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue}}\cf2 \ul \ulc2 \
\
https://fellowship.ai/blog/hyperparam?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue\
\
https://medium.com/@medhaa/three-things-you-need-to-know-about-machine-learning-99e6f5815aee\
\
http://hyperparameter.space/blog/when-not-to-use-deep-learning/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=Deep%20Learning%20Weekly\
\
}